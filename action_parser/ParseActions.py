import requests
from bs4 import BeautifulSoup
from NormalizeText import *

def scrape_expomap_page(url):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ cli-info —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã expomap.ru
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Linux Arch; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        response = requests.get(url, headers=headers, timeout=1000)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')

        cli_info_elements = soup.find_all('div', class_='cli-info')

        print(f"–ù–∞–π–¥–µ–Ω–æ {len(cli_info_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ cli-info")

        events_data = []

        for index, cli_info in enumerate(cli_info_elements, 1):
            event_data = {
                'id': index,
                'data': {}  # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            }

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            # 1. –ó–∞–≥–æ–ª–æ–≤–æ–∫
            header = cli_info.find('header', class_='header-cli-title-pc')
            if header:
                title_div = header.find('div', class_='cli-title')
                if title_div:
                    title_link = title_div.find('a')
                    if title_link:
                        event_data['data']['title'] = title_link.get_text(strip=True)
                        event_data['data']['title_link'] = title_link.get('href', '')

            # 2. –û–ø–∏—Å–∞–Ω–∏–µ
            descr = cli_info.find('div', class_='cli-descr')
            if descr:
                event_data['data']['description'] = descr.get_text(strip=True)

            # 3. –î–∞—Ç–∞
            date_div = cli_info.find('div', class_='cli-date')
            if date_div:
                event_data['data']['date'] = date_div.get_text(strip=True)

            # 4. –ú–µ—Å—Ç–æ
            place_div = cli_info.find('div', class_='cli-place')
            if place_div:
                event_data['data']['place'] = place_div.get_text(strip=True)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –º–µ—Å—Ç–∞
                links = place_div.find_all('a')
                if len(links) >= 2:
                    event_data['data']['country'] = links[0].get_text(strip=True)
                    event_data['data']['city'] = links[1].get_text(strip=True)
                    if len(links) >= 3:
                        event_data['data']['venue'] = links[2].get_text(strip=True)

            # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            stats_div = cli_info.find('aside', class_='right_grey_block')
            if stats_div:
                event_data['data']['statistics'] = str.removeprefix(stats_div.get_text(strip=True), "–ú–∞—Å—à—Ç–∞–± –≤—ã—Å—Ç–∞–≤–∫–∏:")

            # 6. –ü–æ–¥—Ä–æ–±–Ω–µ–µ
            sites = cli_info.find("a", class_="button icon-sm")
            if sites:
                event_data['data']['site'] = sites.get("href")

            events_data.append(event_data)

        return events_data

    except requests.exceptions.RequestException as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
        return None
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
        return None


def get_events():
    # URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    url = "https://expomap.ru/expo/theme/ekologiya-ochistka-utilizatsiya/country/russia/"

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    events = scrape_expomap_page(url)

    if events:
        result = ""
        
        print(f"\n–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω–æ {len(events)} —Å–æ–±—ã—Ç–∏–π")

        print("\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ–±—ã—Ç–∏—è—Ö:")
        for event in events:
            data = event['data']
            
            result += f"\n{'='*60}\n"
            result += f"üé™ –°–û–ë–´–¢–ò–ï #{event['id']}\n"
            result += f"{'='*60}\n"

            result += f"üìå –ù–∞–∑–≤–∞–Ω–∏–µ: {data.get('title', '‚ùå –ù–µ —É–∫–∞–∑–∞–Ω–æ')}\n"
            result += f"üìù –û–ø–∏—Å–∞–Ω–∏–µ: {str.strip(data.get('description', '‚ùå –ù–µ —É–∫–∞–∑–∞–Ω–æ'))}\n"
            result += f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {format_stats(data.get('statistics', '‚ùå –ù–µ —É–∫–∞–∑–∞–Ω–æ'))}\n"
            result += f"üìÖ –î–∞—Ç–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è: {parse_date_string(data.get('date', '‚ùå –ù–µ —É–∫–∞–∑–∞–Ω–æ'))}\n"
            result += f"üìç –ú–µ—Å—Ç–æ: {data.get('place', '‚ùå –ù–µ —É–∫–∞–∑–∞–Ω–æ')}\n"
            result += f"üîó –ü–æ–¥—Ä–æ–±–Ω–µ–µ: https://expomap.ru{data.get('site', '‚ùå –ù–µ—Ç —Å—Å—ã–ª–∫–∏')}\n"

            result += f"{'='*60}\n\n"

        return result
    
    return "–æ—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è - –Ω–µ—Ç —ç–≤–µ–Ω—Ç–æ–≤" 


if __name__ == "__main__":
    print(get_events())